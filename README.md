# Neural Network from Scratch in Python

## Description
This project implements a basic feedforward neural network from scratch in Python. It supports forward and backward propagation, multiple layers, activation functions, loss calculation, and training using gradient descent.

## Features
- Fully connected layers (Dense layers)  
- Activation functions (ReLU, Softmax)  
- Loss functions (Categorical Cross-Entropy)  
- Gradient descent optimizer (Adam)  
- L2 regularization on weights and biases  
- Training loop example using a synthetic spiral dataset  
- Validation with accuracy calculation  

## Usage
1. Clone the repository  
2. Install dependencies:
